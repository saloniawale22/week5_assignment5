{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "pL8HdENDrkOa"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Banking Customer Churn Prediction Dataset/Churn_Modelling.csv')  # Replace with your dataset's file path"
      ],
      "metadata": {
        "id": "tmSpJgjvtJHC"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "# Dropping unnecessary columns\n",
        "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
      ],
      "metadata": {
        "id": "ghRHQHzOtJDw"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical variables\n",
        "label_encoder_geography = LabelEncoder()\n",
        "label_encoder_gender = LabelEncoder()\n",
        "\n",
        "data['Geography'] = label_encoder_geography.fit_transform(data['Geography'])\n",
        "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])"
      ],
      "metadata": {
        "id": "_JVEpT7FtJAl"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into features and target\n",
        "X = data.drop('Exited', axis=1).values\n",
        "y = data['Exited'].values"
      ],
      "metadata": {
        "id": "VRURQcLKtI-Y"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "uHlfMk5FtI7g"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_data(texts, labels, vocab_size=10000, max_length=100):\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    return padded_sequences, labels, tokenizer, sequences"
      ],
      "metadata": {
        "id": "rIcQ2i2j7Tp4"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "vcAp6_cntI4x"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping data for RNN input (samples, time_steps, features)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "8NQ6qtLptI2R"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(range(0,4))\n",
        "X = X.reshape(1,4)\n",
        "y=np.array(range(7,8))\n",
        "y= y.reshape(-1,1)\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPwyq_R50si3",
        "outputId": "56e4cff4-f82c-423c-e467-672488bd44d9"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 1, 2, 3]]), array([[7]]))"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_data(texts, labels, vocab_size=10000, max_length=100):\n",
        "    # Flatten the input texts if they are multi-dimensional\n",
        "    texts = [str(item) for sublist in texts for item in sublist]  # Flatten and convert to strings\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    return padded_sequences, labels, tokenizer, sequences"
      ],
      "metadata": {
        "id": "PPSltZBO7dek"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6P6RyDV9LNY",
        "outputId": "02eecf19-b580-4c76-cfcf-fae6e41114a9"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()"
      ],
      "metadata": {
        "id": "6fpqII309inz"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the SimpleRNN layer\n",
        "model.add(SimpleRNN(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d8nz8kztIxk",
        "outputId": "88ec4c56-9207-49c6-c88c-1df9fec1d2b0"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(range(0,16))\n",
        "X = X.reshape(-1,4,4)\n",
        "y=np.array(range(7,8))\n",
        "y= y.reshape(-1,1)\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucitxj101NK6",
        "outputId": "c3c48d6b-276e-42a6-bc20-4dc120eae96c"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11],\n",
              "         [12, 13, 14, 15]]]),\n",
              " array([[7]]))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "glTvdJrXuJ6k"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YCBpVAtUuDh_"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WPNqmY8uDef",
        "outputId": "4d949e63-fd8d-48ff-d982-ba30a4771cc3"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6851 - loss: 0.5894 - val_accuracy: 0.8210 - val_loss: 0.4206\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4408 - val_accuracy: 0.8290 - val_loss: 0.3990\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4142 - val_accuracy: 0.8435 - val_loss: 0.3851\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.4000 - val_accuracy: 0.8515 - val_loss: 0.3748\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3807 - val_accuracy: 0.8575 - val_loss: 0.3652\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.3662 - val_accuracy: 0.8575 - val_loss: 0.3587\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.3655 - val_accuracy: 0.8545 - val_loss: 0.3553\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.3629 - val_accuracy: 0.8580 - val_loss: 0.3535\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3618 - val_accuracy: 0.8590 - val_loss: 0.3517\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.3623 - val_accuracy: 0.8590 - val_loss: 0.3502\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3665 - val_accuracy: 0.8570 - val_loss: 0.3508\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.3590 - val_accuracy: 0.8555 - val_loss: 0.3504\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3496 - val_accuracy: 0.8585 - val_loss: 0.3497\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.3542 - val_accuracy: 0.8590 - val_loss: 0.3497\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3621 - val_accuracy: 0.8575 - val_loss: 0.3489\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.3607 - val_accuracy: 0.8615 - val_loss: 0.3484\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3591 - val_accuracy: 0.8610 - val_loss: 0.3471\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8542 - loss: 0.3541 - val_accuracy: 0.8585 - val_loss: 0.3487\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3527 - val_accuracy: 0.8610 - val_loss: 0.3484\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.3532 - val_accuracy: 0.8590 - val_loss: 0.3480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ObYC0FXuADQ",
        "outputId": "28964bd1-7801-4607-cbe4-f31b1d574292"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8587 - loss: 0.3505\n",
            "Test Loss: 0.3480135202407837\n",
            "Test Accuracy: 0.859000027179718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q5V1WS45bp-",
        "outputId": "9cd24265-6364-408f-fa3f-c7c315b3ac73"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1560   47]\n",
            " [ 233  160]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92      1607\n",
            "           1       0.77      0.41      0.53       393\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.82      0.69      0.73      2000\n",
            "weighted avg       0.85      0.86      0.84      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting and visualizing the results\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKCvxx7Jt_6Z",
        "outputId": "35e33d87-7f12-4e8f-93b7-e398fae973cf"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(range(0,9))\n",
        "X = X.reshape(3,3)\n",
        "y=np.array(range(5,8))\n",
        "y= y.reshape(-1,1)\n",
        "y.shape, X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz8_mDo51bWt",
        "outputId": "d0ce4021-e94c-4927-b1d2-27fbf7a00967"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 1),\n",
              " array([[0, 1, 2],\n",
              "        [3, 4, 5],\n",
              "        [6, 7, 8]]),\n",
              " array([[5],\n",
              "        [6],\n",
              "        [7]]))"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimental Models with Sequential Data\n",
        "# First Model\n",
        "X_exp1 = np.array(range(0, 4))\n",
        "X_exp1 = X_exp1.reshape(1, 4, 1)  # Reshape for (samples, time_steps, features)\n",
        "y_exp1 = np.array(range(7, 8)).reshape(-1, 1)  # Reshape for (samples, output_dim)\n",
        "\n",
        "model_exp1 = Sequential()\n",
        "model_exp1.add(SimpleRNN(1, input_shape=(4, 1), activation='tanh'))\n",
        "model_exp1.add(Dense(units=1, activation='relu'))\n",
        "model_exp1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_exp1.fit(X_exp1, y_exp1, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nk2ddB-4iTz",
        "outputId": "c273f5d6-a16a-4180-e37c-1903c64218d6"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 29.9095\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 29.8870\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 29.8645\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 29.8420\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 29.8196\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 29.7971\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 29.7747\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 29.7523\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 29.7299\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 29.7075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dca068eb520>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second Model\n",
        "X_exp2 = np.array(range(0, 16))\n",
        "X_exp2 = X_exp2.reshape(-1, 4, 4)  # Reshape for (samples, time_steps, features)\n",
        "y_exp2 = np.array(range(7, 8)).reshape(-1, 1)  # Reshape for (samples, output_dim)\n",
        "\n",
        "model_exp2 = Sequential()\n",
        "model_exp2.add(SimpleRNN(1, input_shape=(4, 4), activation='tanh'))\n",
        "model_exp2.add(Dense(units=1, activation='relu'))\n",
        "model_exp2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_exp2.fit(X_exp2, y_exp2, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6kwc7T44iQP",
        "outputId": "b37d06c2-e970-416b-dcd2-c5c6d39da574"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 49.0000\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 49.0000\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 49.0000\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 49.0000\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 49.0000\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 49.0000\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 49.0000\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 49.0000\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 49.0000\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 49.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dc9ffa77220>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third Model\n",
        "X_exp3 = np.array(range(0, 9))\n",
        "X_exp3 = X_exp3.reshape(3, 3, 1)  # Reshape for (samples, time_steps, features)\n",
        "y_exp3 = np.array(range(5, 8)).reshape(-1, 1)  # Reshape for (samples, output_dim)\n",
        "\n",
        "model_exp3 = Sequential()\n",
        "model_exp3.add(SimpleRNN(1, input_shape=(3, 1), activation='tanh'))\n",
        "model_exp3.add(Dense(units=1, activation='relu'))\n",
        "model_exp3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_exp3.fit(X_exp3, y_exp3, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FsosYN44iNa",
        "outputId": "60f1ece5-287b-4777-f01a-44d1eae06403"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 36.6667\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 36.6667\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 36.6667\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 36.6667\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 36.6667\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 36.6667\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 36.6667\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 36.6667\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 36.6667\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 36.6667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dc9ff727190>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get weights and biases of each layer\n",
        "print(\"\\nWeights and Biases of the Model:\")\n",
        "\n",
        "# Assuming you want weights from model_exp3, replace 'model' with 'model_exp3'\n",
        "model = model_exp3  # Or model_exp1, model_exp2, depending on your needs\n",
        "\n",
        "# Get weights and biases of the SimpleRNN layer\n",
        "rnn_weights = model.layers[0].get_weights()  # Simple RNN Layer\n",
        "print(\"\\nSimpleRNN Layer Weights and Biases:\")\n",
        "print(f\"RNN Weights Shape: {rnn_weights[0].shape}\")\n",
        "print(f\"RNN Biases Shape: {rnn_weights[1].shape}\")\n",
        "\n",
        "# Get weights and biases of the output (Dense) layer\n",
        "dense_weights = model.layers[1].get_weights()  # Output Dense Layer\n",
        "print(\"\\nDense Layer Weights and Biases:\")\n",
        "print(f\"Dense Weights Shape: {dense_weights[0].shape}\")\n",
        "print(f\"Dense Biases Shape: {dense_weights[1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCRHrXN9-0nR",
        "outputId": "d055282c-9619-4164-b5cd-d7aec3b09c3b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weights and Biases of the Model:\n",
            "\n",
            "SimpleRNN Layer Weights and Biases:\n",
            "RNN Weights Shape: (1, 1)\n",
            "RNN Biases Shape: (1, 1)\n",
            "\n",
            "Dense Layer Weights and Biases:\n",
            "Dense Weights Shape: (1, 1)\n",
            "Dense Biases Shape: (1,)\n"
          ]
        }
      ]
    }
  ]
}